{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce7e0be4",
   "metadata": {},
   "source": [
    "# Green Taxi Data Pipeline - PostgreSQL Integration\n",
    "Load November 2025 green taxi data from parquet and insert into PostgreSQL database running in Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f74ed",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dceb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb74cc",
   "metadata": {},
   "source": [
    "## Section 2: Load Parquet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fca7e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet file: /workspaces/Data-Engineering-Zoomcamp/pipeline/data/green_tripdata_2025-11.parquet\n",
      "\n",
      "DataFrame loaded successfully!\n",
      "Shape: (46912, 21)\n",
      "\n",
      "Columns: ['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime', 'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge', 'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge', 'cbd_congestion_fee']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>cbd_congestion_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:34:48</td>\n",
       "      <td>2025-11-01 00:41:39</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:18:52</td>\n",
       "      <td>2025-11-01 00:24:27</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 01:03:14</td>\n",
       "      <td>2025-11-01 01:15:24</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>13.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:10:57</td>\n",
       "      <td>2025-11-01 00:24:53</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>24.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-01 00:03:48</td>\n",
       "      <td>2025-11-01 00:19:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2025-11-01 00:34:48   2025-11-01 00:41:39                  N   \n",
       "1         2  2025-11-01 00:18:52   2025-11-01 00:24:27                  N   \n",
       "2         2  2025-11-01 01:03:14   2025-11-01 01:15:24                  N   \n",
       "3         2  2025-11-01 00:10:57   2025-11-01 00:24:53                  N   \n",
       "4         1  2025-11-01 00:03:48   2025-11-01 00:19:38                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            74            42              1.0           0.74   \n",
       "1         1.0            74            42              2.0           0.95   \n",
       "2         1.0            83           160              1.0           2.19   \n",
       "3         1.0           166           127              1.0           5.44   \n",
       "4         1.0           166           262              1.0           3.20   \n",
       "\n",
       "   fare_amount  ...  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          7.2  ...      0.5        1.94           0.0        NaN   \n",
       "1          7.2  ...      0.5        0.00           0.0        NaN   \n",
       "2         13.5  ...      0.5        5.00           0.0        NaN   \n",
       "3         24.7  ...      0.5        0.50           0.0        NaN   \n",
       "4         18.4  ...      1.5        1.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    1.0         11.64           1.0        1.0   \n",
       "1                    1.0          9.70           2.0        1.0   \n",
       "2                    1.0         21.00           1.0        1.0   \n",
       "3                    1.0         27.70           1.0        1.0   \n",
       "4                    1.0         24.65           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  cbd_congestion_fee  \n",
       "0                  0.00                 0.0  \n",
       "1                  0.00                 0.0  \n",
       "2                  0.00                 0.0  \n",
       "3                  0.00                 0.0  \n",
       "4                  2.75                 0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the green taxi parquet file\n",
    "parquet_path = Path('/workspaces/Data-Engineering-Zoomcamp/pipeline/data/green_tripdata_2025-11.parquet')\n",
    "\n",
    "print(f\"Loading parquet file: {parquet_path}\")\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "print(f\"\\nDataFrame loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a674391",
   "metadata": {},
   "source": [
    "## Section 3: Establish PostgreSQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cd01c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL Connection Parameters:\n",
      "  Host: localhost\n",
      "  Port: 5432\n",
      "  Database: ny_taxi\n",
      "  User: root\n",
      "\n",
      "âœ“ Successfully connected to PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "# PostgreSQL connection parameters\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'ny_taxi',\n",
    "    'user': 'root',\n",
    "    'password': 'root'\n",
    "}\n",
    "\n",
    "# Create connection string for SQLAlchemy\n",
    "connection_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "\n",
    "print(\"PostgreSQL Connection Parameters:\")\n",
    "print(f\"  Host: {db_config['host']}\")\n",
    "print(f\"  Port: {db_config['port']}\")\n",
    "print(f\"  Database: {db_config['database']}\")\n",
    "print(f\"  User: {db_config['user']}\")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    connection = engine.connect()\n",
    "    print(\"\\nâœ“ Successfully connected to PostgreSQL!\")\n",
    "    connection.close()\n",
    "except Exception as e:\n",
    "    print(f\"\\nâœ— Connection failed: {e}\")\n",
    "    print(\"Make sure the PostgreSQL container is running with:\")\n",
    "    print(\"  docker run -it --rm -e POSTGRES_USER='root' -e POSTGRES_PASSWORD='root' -e POSTGRES_DB='ny_taxi' -v ny_taxi_postgres_data:/var/lib/postgresql -p 5432:5432 postgres:18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a8ab20",
   "metadata": {},
   "source": [
    "## Section 4: Create Table and Insert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc5c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into PostgreSQL table 'green_taxi'...\n",
      "âœ“ Successfully inserted 46912 rows into 'green_taxi' table!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create engine and insert data into PostgreSQL\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    # Convert datetime columns to ensure proper formatting\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Insert data into PostgreSQL table\n",
    "    # if_exists: 'replace' will drop and recreate the table; 'append' adds to existing; 'fail' raises error\n",
    "    print(\"Inserting data into PostgreSQL table 'green_taxi'...\")\n",
    "    df_copy.to_sql('green_taxi', engine, if_exists='replace', index=False, chunksize=5000)\n",
    "    \n",
    "    print(f\"âœ“ Successfully inserted {len(df)} rows into 'green_taxi' table!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error inserting data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4652f",
   "metadata": {},
   "source": [
    "## Section 5: Execute SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f98eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Table 'green_taxi' contains 46912 rows\n"
     ]
    }
   ],
   "source": [
    "# Check table size and row count\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    query = \"SELECT COUNT(*) as row_count FROM green_taxi;\"\n",
    "    result = pd.read_sql(query, engine)\n",
    "    print(f\"âœ“ Table 'green_taxi' contains {result['row_count'][0]} rows\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error querying table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1f41b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows from green_taxi table:\n",
      "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
      "0         2  2025-11-01 00:34:48   2025-11-01 00:41:39                  N   \n",
      "1         2  2025-11-01 00:18:52   2025-11-01 00:24:27                  N   \n",
      "2         2  2025-11-01 01:03:14   2025-11-01 01:15:24                  N   \n",
      "3         2  2025-11-01 00:10:57   2025-11-01 00:24:53                  N   \n",
      "4         1  2025-11-01 00:03:48   2025-11-01 00:19:38                  N   \n",
      "\n",
      "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
      "0         1.0            74            42              1.0           0.74   \n",
      "1         1.0            74            42              2.0           0.95   \n",
      "2         1.0            83           160              1.0           2.19   \n",
      "3         1.0           166           127              1.0           5.44   \n",
      "4         1.0           166           262              1.0           3.20   \n",
      "\n",
      "   fare_amount  ...  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
      "0          7.2  ...      0.5        1.94           0.0       None   \n",
      "1          7.2  ...      0.5        0.00           0.0       None   \n",
      "2         13.5  ...      0.5        5.00           0.0       None   \n",
      "3         24.7  ...      0.5        0.50           0.0       None   \n",
      "4         18.4  ...      1.5        1.00           0.0       None   \n",
      "\n",
      "  improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
      "0                   1.0         11.64           1.0        1.0   \n",
      "1                   1.0          9.70           2.0        1.0   \n",
      "2                   1.0         21.00           1.0        1.0   \n",
      "3                   1.0         27.70           1.0        1.0   \n",
      "4                   1.0         24.65           1.0        1.0   \n",
      "\n",
      "   congestion_surcharge  cbd_congestion_fee  \n",
      "0                  0.00                 0.0  \n",
      "1                  0.00                 0.0  \n",
      "2                  0.00                 0.0  \n",
      "3                  0.00                 0.0  \n",
      "4                  2.75                 0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display query results as DataFrame - Sample data\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    query = \"SELECT * FROM green_taxi LIMIT 5;\"\n",
    "    sample_df = pd.read_sql(query, engine)\n",
    "    print(\"Sample rows from green_taxi table:\")\n",
    "    print(sample_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error reading sample data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d0cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aggregate queries - Revenue analysis\n",
    "# try:\n",
    "#     engine = create_engine(connection_string)\n",
    "    \n",
    "#     # Total revenue by payment type\n",
    "#     query = \"\"\"\n",
    "#     SELECT \n",
    "#         payment_type,\n",
    "#         COUNT(*) as trip_count,\n",
    "#         ROUND(SUM(total_amount)::numeric, 2) as total_revenue,\n",
    "#         ROUND(AVG(total_amount)::numeric, 2) as avg_fare\n",
    "#     FROM green_taxi\n",
    "#     GROUP BY payment_type\n",
    "#     ORDER BY total_revenue DESC;\n",
    "#     \"\"\"\n",
    "    \n",
    "#     revenue_df = pd.read_sql(query, engine)\n",
    "#     print(\"\\nðŸ“Š Revenue Analysis by Payment Type:\")\n",
    "#     print(revenue_df)\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"âœ— Error in aggregate query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21aaa734-8174-4b5f-88ba-376915cf0e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 3. For the trips in November 2025, how many trips had a trip_distance of less than or equal to 1 mile?:\n",
      "   trips_le_1_mile\n",
      "0             8007\n"
     ]
    }
   ],
   "source": [
    "# Question 3. For the trips in November 2025, how many trips had a trip_distance of less than or equal to 1 mile?\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    query = \"\"\"SELECT COUNT(*) AS trips_le_1_mile\n",
    "                FROM green_taxi\n",
    "                WHERE lpep_pickup_datetime >= '2025-11-01'\n",
    "                AND lpep_pickup_datetime <  '2025-12-01'\n",
    "                AND trip_distance <= 1;\"\"\"\n",
    "    sample_df = pd.read_sql(query, engine)\n",
    "    print(\"Question 3. For the trips in November 2025, how many trips had a trip_distance of less than or equal to 1 mile?:\")\n",
    "    print(sample_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error reading sample data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2171c39-e20a-4c45-af3b-1dbe71da5321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which was the pick up day with the longest trip distance?:\n",
      "   pickup_day  max_dist\n",
      "0  2025-11-14     88.03\n"
     ]
    }
   ],
   "source": [
    "# Question 4. Which was the pick up day with the longest trip distance? Only consider trips with trip_distance less than 100 miles. \n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    query = \"\"\"SELECT CAST(lpep_pickup_datetime AS DATE) AS pickup_day,\n",
    "                       MAX(trip_distance) AS max_dist\n",
    "                FROM green_taxi\n",
    "                WHERE lpep_pickup_datetime >= '2025-11-01'\n",
    "                  AND lpep_pickup_datetime <  '2025-12-01'\n",
    "                  AND trip_distance < 100\n",
    "                GROUP BY 1\n",
    "                ORDER BY max_dist DESC\n",
    "                LIMIT 1;\"\"\"\n",
    "    sample_df = pd.read_sql(query, engine)\n",
    "    print(\"Which was the pick up day with the longest trip distance?:\")\n",
    "    print(sample_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error reading sample data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce021258-ea9a-4c6b-b9d8-a3955673a5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaec1bf-0fd5-4357-8ff2-6a020f313f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac7277e6",
   "metadata": {},
   "source": [
    "## Section 7: Download and Ingest Taxi Zones Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8627bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading taxi_zone_lookup.csv from GitHub...\n",
      "URL: https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "\n",
      "âœ“ Download successful!\n",
      "  Saved to: /workspaces/Data-Engineering-Zoomcamp/pipeline/data/taxi_zone_lookup_download.csv\n",
      "  File size: 12,322 bytes\n"
     ]
    }
   ],
   "source": [
    "# Download taxi_zone_lookup.csv from GitHub using requests\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\"\n",
    "zones_download_path = '/workspaces/Data-Engineering-Zoomcamp/pipeline/data/taxi_zone_lookup_download.csv'\n",
    "\n",
    "print(\"Downloading taxi_zone_lookup.csv from GitHub...\")\n",
    "print(f\"URL: {url}\\n\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Save the file\n",
    "    with open(zones_download_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    file_size = Path(zones_download_path).stat().st_size\n",
    "    print(f\"âœ“ Download successful!\")\n",
    "    print(f\"  Saved to: {zones_download_path}\")\n",
    "    print(f\"  File size: {file_size:,} bytes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Download failed: {e}\")\n",
    "    print(\"  Trying alternative source...\")\n",
    "    zones_download_path = '/workspaces/Data-Engineering-Zoomcamp/pipeline/taxi_zone_lookup.csv'\n",
    "    print(f\"  Will use local file: {zones_download_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7f9428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading zones data from CSV...\n",
      "âœ“ Zones data loaded successfully!\n",
      "  Shape: (265, 4)\n",
      "  Columns: ['LocationID', 'Borough', 'Zone', 'service_zone']\n",
      "\n",
      "First 5 rows:\n",
      "   LocationID        Borough                     Zone service_zone\n",
      "0           1            EWR           Newark Airport          EWR\n",
      "1           2         Queens              Jamaica Bay    Boro Zone\n",
      "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
      "3           4      Manhattan            Alphabet City  Yellow Zone\n",
      "4           5  Staten Island            Arden Heights    Boro Zone\n"
     ]
    }
   ],
   "source": [
    "# Load zones data from CSV\n",
    "print(\"\\nLoading zones data from CSV...\")\n",
    "\n",
    "# Try downloaded file first, then fall back to local\n",
    "zones_path = zones_download_path if Path(zones_download_path).exists() else '/workspaces/Data-Engineering-Zoomcamp/pipeline/taxi_zone_lookup.csv'\n",
    "\n",
    "zones_df = pd.read_csv(zones_path)\n",
    "\n",
    "print(f\"âœ“ Zones data loaded successfully!\")\n",
    "print(f\"  Shape: {zones_df.shape}\")\n",
    "print(f\"  Columns: {zones_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(zones_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e772d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserting zones data into PostgreSQL table 'zones'...\n",
      "âœ“ Successfully inserted 265 zones into 'zones' table!\n"
     ]
    }
   ],
   "source": [
    "# Ingest zones data into PostgreSQL 'zones' table\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    print(\"\\nInserting zones data into PostgreSQL table 'zones'...\")\n",
    "    zones_df.to_sql('zones', engine, if_exists='replace', index=False, chunksize=5000)\n",
    "    \n",
    "    print(f\"âœ“ Successfully inserted {len(zones_df)} zones into 'zones' table!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error inserting zones data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f7bda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Zones table verified!\n",
      "  Total zones: 265\n",
      "\n",
      "Sample zones from database:\n",
      "   LocationID        Borough                     Zone service_zone\n",
      "0           1            EWR           Newark Airport          EWR\n",
      "1           2         Queens              Jamaica Bay    Boro Zone\n",
      "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
      "3           4      Manhattan            Alphabet City  Yellow Zone\n",
      "4           5  Staten Island            Arden Heights    Boro Zone\n"
     ]
    }
   ],
   "source": [
    "# Verify zones table creation\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    # Count zones in table\n",
    "    count_query = \"SELECT COUNT(*) as zone_count FROM zones;\"\n",
    "    count_result = pd.read_sql(count_query, engine)\n",
    "    zone_count = count_result['zone_count'][0]\n",
    "    \n",
    "    print(f\"\\nâœ“ Zones table verified!\")\n",
    "    print(f\"  Total zones: {zone_count}\")\n",
    "    \n",
    "    # Display sample zones\n",
    "    sample_query = \"SELECT * FROM zones LIMIT 5;\"\n",
    "    sample_zones = pd.read_sql(sample_query, engine)\n",
    "    print(f\"\\nSample zones from database:\")\n",
    "    print(sample_zones)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error verifying zones table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "310379c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Sample trips enriched with zone information:\n",
      "   VendorID lpep_pickup_datetime lpep_dropoff_datetime  trip_distance  \\\n",
      "0         2  2025-11-01 00:34:48   2025-11-01 00:41:39           0.74   \n",
      "1         2  2025-11-01 00:18:52   2025-11-01 00:24:27           0.95   \n",
      "2         2  2025-11-01 01:03:14   2025-11-01 01:15:24           2.19   \n",
      "3         2  2025-11-01 00:10:57   2025-11-01 00:24:53           5.44   \n",
      "4         1  2025-11-01 00:03:48   2025-11-01 00:19:38           3.20   \n",
      "5         1  2025-11-01 00:42:13   2025-11-01 01:04:50           5.10   \n",
      "6         2  2025-11-01 00:05:41   2025-11-01 00:39:20           9.80   \n",
      "7         2  2025-11-01 00:42:14   2025-11-01 01:13:20           5.01   \n",
      "8         2  2025-11-01 00:03:08   2025-11-01 00:06:27           0.63   \n",
      "9         2  2025-11-01 00:56:33   2025-11-01 01:01:34           1.15   \n",
      "\n",
      "   fare_amount  total_amount          pickup_zone pickup_borough  \\\n",
      "0          7.2         11.64    East Harlem North      Manhattan   \n",
      "1          7.2          9.70    East Harlem North      Manhattan   \n",
      "2         13.5         21.00     Elmhurst/Maspeth         Queens   \n",
      "3         24.7         27.70  Morningside Heights      Manhattan   \n",
      "4         18.4         24.65  Morningside Heights      Manhattan   \n",
      "5         26.8         39.35           Greenpoint       Brooklyn   \n",
      "6         43.6         59.52     Elmhurst/Maspeth         Queens   \n",
      "7         28.9         41.88   DUMBO/Vinegar Hill       Brooklyn   \n",
      "8          5.1          9.12             Steinway         Queens   \n",
      "9          7.9         10.40              Jamaica         Queens   \n",
      "\n",
      "               dropoff_zone dropoff_borough  \n",
      "0      Central Harlem North       Manhattan  \n",
      "1      Central Harlem North       Manhattan  \n",
      "2            Middle Village          Queens  \n",
      "3                    Inwood       Manhattan  \n",
      "4            Yorkville East       Manhattan  \n",
      "5              Clinton East       Manhattan  \n",
      "6  Financial District North       Manhattan  \n",
      "7       UN/Turtle Bay South       Manhattan  \n",
      "8                  Steinway          Queens  \n",
      "9                   Jamaica          Queens  \n"
     ]
    }
   ],
   "source": [
    "# Join green_taxi trips with zones lookup for enriched analysis\n",
    "# Note: PostgreSQL stores column names as lowercase\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        g.\"VendorID\",\n",
    "        g.\"lpep_pickup_datetime\",\n",
    "        g.\"lpep_dropoff_datetime\",\n",
    "        g.\"trip_distance\",\n",
    "        g.\"fare_amount\",\n",
    "        g.\"total_amount\",\n",
    "        pz.\"Zone\" as pickup_zone,\n",
    "        pz.\"Borough\" as pickup_borough,\n",
    "        dz.\"Zone\" as dropoff_zone,\n",
    "        dz.\"Borough\" as dropoff_borough\n",
    "    FROM green_taxi g\n",
    "    LEFT JOIN zones pz ON g.\"PULocationID\" = pz.\"LocationID\"\n",
    "    LEFT JOIN zones dz ON g.\"DOLocationID\" = dz.\"LocationID\"\n",
    "    LIMIT 10;\n",
    "    \"\"\"\n",
    "    \n",
    "    joined_result = pd.read_sql(query, engine)\n",
    "    print(\"\\nâœ“ Sample trips enriched with zone information:\")\n",
    "    print(joined_result)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error in join query: {e}\")\n",
    "    print(\"\\n  Note: Column names are case-sensitive in PostgreSQL when using quotes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49fc30ee-ec3b-4a5c-a8c8-614f9a443111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which was the pickup zone with the largest total_amount :\n",
      "         pickup_zone  total_amt\n",
      "0  East Harlem North    9281.92\n"
     ]
    }
   ],
   "source": [
    "# Question 5. Which was the pickup zone with the largest total_amount (sum of all trips) on November 18th, 2025? \n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    query = \"\"\"SELECT pz.\"Zone\" AS pickup_zone,\n",
    "                       SUM(g.\"total_amount\") AS total_amt\n",
    "                FROM green_taxi g\n",
    "                LEFT JOIN zones pz ON g.\"PULocationID\" = pz.\"LocationID\"\n",
    "                LEFT JOIN zones dz ON g.\"DOLocationID\" = dz.\"LocationID\"\n",
    "                WHERE CAST(g.\"lpep_pickup_datetime\" AS DATE) = '2025-11-18'\n",
    "                GROUP BY 1\n",
    "                ORDER BY total_amt DESC\n",
    "                LIMIT 1;\n",
    "            \"\"\"\n",
    "    sample_df = pd.read_sql(query, engine)\n",
    "    print(\"Which was the pickup zone with the largest total_amount :\")\n",
    "    print(sample_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error reading sample data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe9b53-5d86-49ce-8f64-1d8f61d0597c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37c1ea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Question 6: Drop-off zone with largest tip from 'East Harlem North' (Nov 2025)\n",
      "     dropoff_zone  tip_amount lpep_pickup_datetime        pickup_zone\n",
      "0  Yorkville West       81.89  2025-11-30 16:30:27  East Harlem North\n"
     ]
    }
   ],
   "source": [
    "# Question 6: For passengers picked up in \"East Harlem North\" in Nov 2025, \n",
    "# which drop-off zone had the largest tip?\n",
    "\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        dz.\"Zone\" as dropoff_zone,\n",
    "        t.\"tip_amount\",\n",
    "        t.\"lpep_pickup_datetime\",\n",
    "        pz.\"Zone\" as pickup_zone\n",
    "    FROM green_taxi t\n",
    "    JOIN zones pz ON t.\"PULocationID\" = pz.\"LocationID\"\n",
    "    JOIN zones dz ON t.\"DOLocationID\" = dz.\"LocationID\"\n",
    "    WHERE pz.\"Zone\" = 'East Harlem North'\n",
    "        AND EXTRACT(YEAR FROM t.\"lpep_pickup_datetime\") = 2025\n",
    "        AND EXTRACT(MONTH FROM t.\"lpep_pickup_datetime\") = 11\n",
    "    ORDER BY t.\"tip_amount\" DESC\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    \n",
    "    result_q6 = pd.read_sql(query, engine)\n",
    "    \n",
    "    if not result_q6.empty:\n",
    "        print(\"âœ“ Question 6: Drop-off zone with largest tip from 'East Harlem North' (Nov 2025)\")\n",
    "        print(result_q6)\n",
    "    else:\n",
    "        print(\"âš  No trips found from 'East Harlem North' in November 2025\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error: {e}\")\n",
    "    print(\"\\nðŸ’¡ Verify the exact zone name using:\")\n",
    "    print(\"   SELECT DISTINCT \\\"Zone\\\" FROM zones ORDER BY \\\"Zone\\\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e1a51-24ef-475f-a1c4-72cd73e645af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
